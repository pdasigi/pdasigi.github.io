title: Pradeep Dasigi's Homepage
author: pdasigi
email: pradeepd@allenai.org

remote_theme: thelehhman/plainwhite-jekyll
sass:
        sass_dir: _sass
plainwhite:
        name: Pradeep Dasigi
        email: pradeepd@allenai.org
        tagline: Research Scientist at AI2
        date_format: "%b %-d, %Y"
        dark_mode: true

        social_links:
                twitter: pdasigi
                github: pdasigi
                linkedIn: in/pradeepdasigi
                gScholar: Bpd76vcAAAAJ
                sScholar: 2697425

        content: >

          <p>I am a research scientist on the <a href="https://allennlp.org/">AllenNLP</a> team
          at the <a href="https://allenai.org/">Allen Institute for AI</a>. I have been actively involved in developing open language models,
          <a href="https://allenai.org/olmo">OLMo</a> and <a href="https://allenai.org/tulu">Tulu</a>.
          I currently work on post-training language models, and am generally passionate about adapting language models for general use with minimal human effort.</p>
         
          <h2>Research Themes</h2>
          <p>Check out the full list of <a href="https://www.semanticscholar.org/author/Pradeep-Dasigi/2697425?sort=pub-date">my papers</a> for an up-to-date overview of my
          research. The following are the core themes of my work and some associated selected publications.</p>
          <ul>
          <li>
                Open Language Modeling Recipes
                <ul>
                <li><a href="https://www.semanticscholar.org/paper/T%C3%9CLU-3%3A-Pushing-Frontiers-in-Open-Language-Model-Lambert-Morrison/6a7c29829227bfd65ae0ffec294a874bb9ea0871">Tulu 3: Pushing Frotiers in Open Language Model Post-Training</a></li>
                <li><a href="https://www.semanticscholar.org/paper/How-Far-Can-Camels-Go-Exploring-the-State-of-Tuning-Wang-Ivison/fbd2c8089870814449f9254a711041bbae145a82">How Far Can Camels Go? Exploring the State of Instruction Tuning on Open Resources</a></li>
                </ul>
          </li>
          <li>
                Efficient Adaptation of Language Models
                <ul>
                <li><a href="https://www.semanticscholar.org/paper/Large-Scale-Data-Selection-for-Instruction-Tuning-Ivison-Zhang/8c2b2c9cf5f9d4671657cfa6242b19a9290bcb69">Large-Scale Data Selection for Instruction Tuning</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Hybrid-Preferences%3A-Learning-to-Route-Instances-for-Miranda-Wang/cdf06034c58381afe58aed0ed8dc505039055a4f">Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Scalable-Data-Ablation-Approximations-for-Language-Na-Magnusson/0f20baeae798c1638716585a7b896d5885389e62">Scalable Data Ablation Approximations for Language Models through Modular Training and Merging</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Merge-to-Learn%3A-Efficiently-Adding-Skills-to-Models-Morrison-Smith/911045e6713f865ebcef6b95563a92e32b76bcb6">Merge to Learn: Efficiently Adding Skills to Language Models with Model Merging</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Data-Efficient-Finetuning-Using-Cross-Task-Nearest-Ivison-Smith/5eba60c0c5e5f1f0c6c652dfd48b07caeebf13f4">Data-Efficient Finetuning Using Cross-Task Nearest Neighbors</a></li>
                </ul>

          </li>

          <li>
                Robustness to Distribution Shifts
                <ul>
                <li><a href="https://www.semanticscholar.org/paper/TRAM%3A-Bridging-Trust-Regions-and-Sharpness-Aware-Sherborne-Saphra/cce2174048a8e5cf0bc3c9875b32607a02aaf44c">TRAM: Bridging Trust Regions and Sharpness Aware Minimization</a></li>
                <li><a href="https://www.semanticscholar.org/paper/AGRO%3A-Adversarial-Discovery-of-Error-prone-groups-Paranjape-Dasigi/8c87dcaba827e5c1683086c3118fd9bffa7cff5e">AGRO: Adversarial Discovery of Error-prone groups for Robust Optimization</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Generating-Data-to-Mitigate-Spurious-Correlations-Wu-Gardner/1cfe67bad95a16bc249941b829d113d830031cf5">Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets</a></li>
                </ul>
          </li>

          <li>
                Evaluation Benchmarks and Guidelines</li>
                <ul>
                <li><a href="https://www.semanticscholar.org/paper/LongEval%3A-Guidelines-for-Human-Evaluation-of-in-Krishna-Bransom/f1f6c61ed0b80a785e4e5d0d97a454dbe6126c63">LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization</a></li>
                <li><a href="https://www.semanticscholar.org/paper/A-Dataset-of-Information-Seeking-Questions-and-in-Dasigi-Lo/4e3935ef7da6bcbb202ec7f8b285c313cadcd044">A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers</a></li>
                <li><a href="https://www.semanticscholar.org/paper/Quoref%3A-A-Reading-Comprehension-Dataset-with-Dasigi-Liu/3838387ea8dd1bb8c2306be5a63c1c120075c5a2">Quoref: A Reading Comprehension Dataset with Questions Requiring Coreferential Reasoning</a></li>
                <li><a href="https://www.semanticscholar.org/paper/DROP%3A-A-Reading-Comprehension-Benchmark-Requiring-Dua-Wang/dda6fb309f62e2557a071522354d8c2c897a2805">DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs</a></li>
                </ul>
          </ul>
          
          <h2>Mentorship</h2>
                <p>I have been fortunate to work with many talented interns and pre-doctoral researchers over the years.</p>
                <h3>Pre-doctoral researchers</h3>
                <ul>
                <li>Jacob Morrison → PhD student, University of Washington</li>
                <li>Lj Miranda → PhD student, University of Cambridge</li>
                <li>Xinxi Lyu → PhD student, University of Illinois Urbana-Champaign</li>
                </ul>

                <h3>Interns</h3>
                <ul>
                <li>Shakti Senthil, Senior, University of Washington (2025)</li>
                <li>Clara Na, PhD student, Carnegie Mellon University (2023)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/Scalable-Data-Ablation-Approximations-for-Language-Na-Magnusson/0f20baeae798c1638716585a7b896d5885389e62">Scalable Data Ablation Approximations for Language Models through Modular Training and Merging</a></li></ul>
                <li>Arkil Patel, Masters student, McGill University (2023)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/Evaluating-In-Context-Learning-of-Libraries-for-Patel-Reddy/222f289cb96ac4dfef7849cd068af6af02233c52">Evaluating In-Context Learning of Libraries for Code Generation</a></li></ul>
                <li>Tom Sherborne, PhD student, University of Edinburgh (2023)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/TRAM%3A-Bridging-Trust-Regions-and-Sharpness-Aware-Sherborne-Saphra/cce2174048a8e5cf0bc3c9875b32607a02aaf44c">TRAM: Bridging Trust Regions and Sharpness Aware Minimization</a></li></ul>
                <li>Kalpesh Krishna, PhD student, University of Massachusetts, Amherst (2022)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/LongEval%3A-Guidelines-for-Human-Evaluation-of-in-Krishna-Bransom/f1f6c61ed0b80a785e4e5d0d97a454dbe6126c63">LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form Summarization</a></li></ul>
                <li>Revanth Gangi Reddy, PhD student, University of Illinois University of Illinois Urbana-Champaign (2022)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/A-Large-Scale-Study-of-Reranker-Relevance-Feedback-Reddy-Dasigi/1df0c32bd7d008567b271325de7901097c68be28">A Large-Scale Study of Reranker Relevance Feedback at Inference</a></li></ul>
                <li>Bhargavi Paranjape, PhD student, University of Washington (2022)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/AGRO%3A-Adversarial-Discovery-of-Error-prone-groups-Paranjape-Dasigi/8c87dcaba827e5c1683086c3118fd9bffa7cff5e">AGRO: Adversarial Discovery of Error-prone groups for Robust Optimization</a></li></ul>
                <li>Vidhisha Balachandran, PhD student, Carnegie Mellon University (2021)</li>
                <li>Yuxiang Wu, PhD student, University College London (2021)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/Generating-Data-to-Mitigate-Spurious-Correlations-Wu-Gardner/1cfe67bad95a16bc249941b829d113d830031cf5">Generating Data to Mitigate Spurious Correlations in Natural Language Inference Datasets</a></li></ul>
                <li>Ansong Ni, Masters student, Carnegie Mellon University (2020)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/Mitigating-False-Negative-Contexts-in-Question-with-Ni-Gardner/443f889a2d4da14e930586e9416068f91c93a5bb">Mitigating False-Negative Contexts in Multi-document Question Answering with Retrieval Marginalization</a></li></ul>
                <li>James Ferguson, PhD student, University of Washington (2020)</li>
                        <ul><li><a href="https://www.semanticscholar.org/paper/IIRC%3A-A-Dataset-of-Incomplete-Information-Reading-Ferguson-Gardner/01a1f2df34d947d7aa5698ca6fb31c03d15a5183">IIRC: A Dataset of Incomplete Information Reading Comprehension Questions</a></li></ul>
                <li>Zhanming Allan Jie, PhD student, Singapore University of Technology and Design (2019)</li>
                </ul>
                        
          <h2>Podcast</h2>
          <p>I used to be a frequent host on the <a href="https://soundcloud.com/nlp-highlights">NLP Highlights</a> podcast along with other members
          of the AllenNLP team.</p>

plugins:
        - jekyll-seo-tag
